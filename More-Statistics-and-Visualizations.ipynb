{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Statistics Fundamentals Part 2\n",
    "\n",
    "_Authors: Alexander Egorenkov (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "- **Explain** the difference between causation and correlation\n",
    "- **Determine** causality and sampling bias using Directed Acyclic Graphs\n",
    "- **Identify** what missing data is and how to handle it\n",
    "- **Test** a hypothesis using a sample case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Data Source](#data-source)\n",
    "\t- [What are the features/covariates/predictors?](#what-are-the-featurescovariatespredictors)\n",
    "\t- [What is the outcome/response?](#what-is-the-outcomeresponse)\n",
    "\t- [What do you think each row in the dataset represents?](#what-do-you-think-each-row-in-the-dataset-represents)\n",
    "- [Math review](#math-review)\n",
    "\t- [Covariance](#covariance)\n",
    "\t- [Correlation](#correlation)\n",
    "\t- [The variance-covariance matrix](#the-variance-covariance-matrix)\n",
    "- [Causation and Correlation](#causation-and-correlation)\n",
    "\t- [Structure of causal claims](#structure-of-causal-claims)\n",
    "\t- [Why do we care?](#why-do-we-care)\n",
    "\t- [How do we determine if something is causal?](#how-do-we-determine-if-something-is-causal)\n",
    "- [Pearlean Causal DAG model](#pearlean-causal-dag-model)\n",
    "\t- [What is a DAG?](#what-is-a-dag)\n",
    "\t- [It's possible that X causes Y.](#its-possible-that-x-causes-y)\n",
    "\t- [Y causes X.](#y-causes-x)\n",
    "\t- [The correlation between X and Y is not statistically significant.](#the-correlation-between-x-and-y-is-not-statistically-significant)\n",
    "\t- [X or Y may cause one or the other indirectly through another variable.](#x-or-y-may-cause-one-or-the-other-indirectly-through-another-variable)\n",
    "\t- [There is a third common factor that causes both X and Y.](#there-is-a-third-common-factor-that-causes-both-x-and-y)\n",
    "\t- [Both X and Y cause a third variable and the dataset does not represent that third variable evenly.](#both-x-and-y-cause-a-third-variable-and-the-dataset-does-not-represent-that-third-variable-evenly)\n",
    "\t- [Controlled Experiments](#controlled-experiments)\n",
    "\t- [When is it OK to rely on association?](#when-is-it-ok-to-rely-on-association)\n",
    "\t- [How does association relate to causation?](#how-does-association-relate-to-causation)\n",
    "- [Sampling bias](#sampling-bias)\n",
    "\t- [Forms of sampling bias](#forms-of-sampling-bias)\n",
    "\t- [Problems from sampling bias](#problems-from-sampling-bias)\n",
    "\t- [Recovering from sampling bias](#recovering-from-sampling-bias)\n",
    "    - [Stratified random sampling](#stratified-random-sampling)\n",
    "- [Missing data](#missing-data)\n",
    "\t- [Types of missing data](#types-of-missing-data)\n",
    "\t- [De minimis](#de-minimis)\n",
    "\t- [Class imbalance](#class-imbalance)\n",
    "    - [Relation to machine learning](#relation-to-machine-learning)\n",
    "- [Introduction to Hypothesis Testing](#introduction-to-hypothesis-testing)\n",
    "\t- [Validate your findings](#validate-your-findings)\n",
    "\t- [Confidence intervals](#confidence-intervals)\n",
    "\t- [Error types](#error-types)\n",
    "- [Scenario](#scenario)\n",
    "\t- [Exercises](#exercises)\n",
    "\t- [Statistical Tests](#statistical-tests)\n",
    "\t- [Interpret your results](#interpret-your-results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-source\"></a>\n",
    "## Data Source\n",
    "\n",
    "---\n",
    "\n",
    "Today, we’ll use advertising data from an example in the book [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/).\n",
    "- This is a well known, standard introduction to Machine Learning.\n",
    "- The book has a more advanced version, [Elements of Statistical Learning](http://web.stanford.edu/~hastie/ElemStatLearn/), if you are comfortable with Linear Algebra and Statistics approaching the grad level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codealong: Bring in Today's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "# we use index_col to tell Pandas that the first column in the data has row labels\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examine the data with .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions About the Advertising Data\n",
    "\n",
    "Let's pretend you work for the company that manufactures and markets a new device. The company might ask you the following: From the data we currently have, how should we spend  our advertising money in the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-are-the-featurescovariatespredictors\"></a>\n",
    "### What are the features/covariates/predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-the-outcomeresponse\"></a>\n",
    "### What is the outcome/response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-do-you-think-each-row-in-the-dataset-represents\"></a>\n",
    "### What do you think each row in the dataset represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"math-review\"></a>\n",
    "## Math review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"covariance\"></a>\n",
    "### Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance is a measure of the joint variability between two random variables.\n",
    "\n",
    "You can think of this as a measure of linear association. If you have the variance of Y and the variance of X, the covariance is the amount of variance that they share.\n",
    "\n",
    "$$cov(X, Y) = \\frac {\\sum{(x_i - \\bar{X})(y_i - \\bar{Y})}} {n}$$\n",
    "\n",
    "> We can gain insight into covariance by looking closely at this formula. First, observe that the formula effectively pairs the first $x$ data point with the first $y$ data point: $(x_1, y_1)$. All computations are done only on these pairs of points.\n",
    "\n",
    "> Second, let's ask **when would covariance be positive**? From the numerator, covariance would be positive if for all pairs of data points, $(x_i - \\bar{X})$ and $(y_i - \\bar{Y})$ are (1) both positive or (2) both negative. This occurs when: (1) both data points are above their respective means. Or when: (2) both data points are below their respective means! So, if the $x$ data points vary from their mean in the same way the $y$ data points vary from their mean, covariance will be positive.\n",
    "\n",
    "> Third, **might outliers affect covariance?** Yes! Due to the structure of the formula (a sum of terms), a large outlier pair far from the means could strongly pull the covariance in one direction.\n",
    "\n",
    "Expressed using matrix notation:\n",
    "$$cov(\\mathbf{X}, \\mathbf{Y}) = \\mathbb{E}[(\\mathbf{X}-\\mathbb{E}[\\mathbf{X}])(\\mathbf{Y}-\\mathbb{E}[\\mathbf{Y}])]$$\n",
    "\n",
    "A useful special case (used below):\n",
    "\n",
    "$$cov(X, X) = \\frac {\\sum{(x_i - \\bar{X})^2}} {n} = var(X) = \\sigma_X^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"correlation\"></a>\n",
    "### Correlation\n",
    "\n",
    "While covariance is a useful measure, it can be difficult to compare covariances because they are not standardized. \n",
    "\n",
    "In place, we can use the correlation which measures the same effect, but reports it as a range from -1 to 1. 1 means perfect covariance and correlation, 0 means no correlation, and -1 one means perfect inverse correlation.\n",
    "\n",
    "$$corr(X,Y) = \\frac {cov(X,Y)} {\\sigma_X\\sigma_Y} = \\frac {\\mathbb{E}[(\\mathbf{X}-\\mathbb{E}[\\mathbf{X}])(\\mathbf{Y}-\\mathbb{E}[\\mathbf{Y}])]} {\\sigma_X\\sigma_Y}$$\n",
    "\n",
    "Note that the variance is always positive, making the denominator positive. So, the sign of the covariance between $X$ and $Y$ is the same as the sign of their correlation! \n",
    "\n",
    "To better illustrate how correlation refers to how $X$ and $Y$ change together, following are some visual examples. Notice that a correlation number by itself is not always indicative of the relationship of the variables -- always try to supplement 2D correlation with a visual!\n",
    "\n",
    "![](./assets/images/correlation_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"the-variance-covariance-matrix\"></a>\n",
    "### The variance-covariance matrix\n",
    "\n",
    "For our purposes in modeling and machine learning, the fastest way to get a preview of the underlying relationships in our data is to use the variance-covariance matrix.\n",
    "\n",
    "The variance-covariance matrix shows the covariance between every variable in our data.\n",
    "\n",
    "Given $n$ features from $X_1$ to $X_n$, the variance-covariance matrix looks like this (recall that $cov(X, X) = var(X)$):\n",
    "\n",
    "$$\\left[ \\begin{array}{c}\n",
    "var(X_1) & cov(X_1,X_2) & ... & cov(X_1,X_n)  \\\\\n",
    "cov(X_2,X_1) & var(X_2) & ... & cov(X_2,X_n)  \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "cov(X_n,X_1) & cov(X_n,X_2) & ... & var(X_n)\n",
    "\\end{array} \\right]$$\n",
    "\n",
    "By quickly glancing at this matrix, we can gleam insight about which variables might be strongly correlated. This may indicate redundant features and/or may affect some models.\n",
    "\n",
    "If data is mean-centered, every column has its mean subtracted from itself. So, the mean for every column is now 0. You can then compute the variance-covariance matrix as:\n",
    "\n",
    "$$\\frac {X^TX} {n}$$\n",
    "\n",
    "Those of you who have been exposed to linear regression may recognize this term.\n",
    "\n",
    "#### Calculate the variance-covariance matrix. Make sure to first de-mean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the correlation matrix using the built-in `corr` method of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have a lot of data, the correlation matrix may be too difficult to read. It can help to make a plot.\n",
    "\n",
    "#### Use seaborn's `heatmap` function to make a plot of the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, looking at linear association doesn't tell us the whole picture. We can get a more detailed look with a scatter plot matrix.\n",
    "\n",
    "#### Use seaborn's `pairplot` function to make joint scatterplots of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"causation-and-correlation\"></a>\n",
    "## Causation and Correlation\n",
    "---\n",
    "\n",
    "#### Objective: Explain the difference between causation and correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Think of various examples you’ve seen in the media related to food.\n",
    "- [Study links coffee consumption to decreased risk of colorectal cancer](https://news.usc.edu/97761/new-study-links-coffee-consumption-to-decreased-risk-of-colorectal-cancer/)\n",
    "- [Coffee Does Not Decrease Risk of Colorectal Cancer](http://news.cancerconnect.com/coffee-does-not-decrease-risk-of-colorectal-cancer/)\n",
    "- [There's a whole book series based on these Spurious Correlations](http://www.tylervigen.com/spurious-correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is this?**\n",
    "- Sensational headlines?\n",
    "- There is neglect of a robust data analysis.\n",
    "- Causal claims and associations are difficult to convey in an unambiguous way\n",
    "\n",
    "- The above food claims are **correlated**, but may or may not be **causal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"structure-of-causal-claims\"></a>\n",
    "### Structure of causal claims\n",
    "- If X happens, Y must happen\n",
    "- If Y happens, X must have happened \n",
    "  - (You need X and something else for Y to happen)\n",
    "- If X happens, Y will probably happen\n",
    "- If Y happens, X probably happened\n",
    "\n",
    "> **Note:** Properties from definition are not causal. If some something is a triangle, it is implied that it has three sides. However, its being a triangle does not cause it to have three sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"why-do-we-care\"></a>\n",
    "### Why do we care?\n",
    "- Understanding this difference is critical in the data science workflow, especially when Identifying and Acquiring data.\n",
    "- We need to fully articulate our question and use the right data to answer it, including considering any **confounders**.\n",
    "\n",
    "> **Confounders** are unobserved variables that could affect the outcome. If we neglect to include confounding variables in an analysis, we could easily make an inaccurate model. For example, we might falsely assume that eating more ice cream cones causes us to wear fewer layers of clothing. In actuality, eating ice cream is correlated with a confounding variable -- temperature! To make an accurate analysis, we can only conclude that ice cream consumption is _correlated with_ clothing layers.\n",
    "\n",
    "- We don’t want to overstate what our model measures.\n",
    "- Be careful not to say “caused” when you really mean “measured” or “associated”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-do-we-determine-if-something-is-causal\"></a>\n",
    "### How do we determine if something is causal?\n",
    "Causal criteria is one approach to assessing causal relationships.\n",
    "\n",
    "However, it’s very hard to define universal causal criteria.\n",
    "\n",
    "One attempt that is commonly used in the medical field is based on work by Bradford Hill.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He developed a list of “tests” that an analysis must pass in order to indicate a causal relationship:\n",
    "\n",
    "\n",
    "- Strength of association\n",
    "- Consistency\n",
    "- Specificity\n",
    "- Temporality\n",
    "- Biological gradient\n",
    "- Plausibility\n",
    "- Coherence\n",
    "- Experiment\n",
    "- Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strength (effect size)**: A small association does not mean that there is not a causal effect, though the larger the association, the more likely that it is causal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consistency (reproducibility)**: Consistent findings observed by different persons in different places with different samples strengthens the likelihood of an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity**: Causation is likely if there is a very specific population at a specific site and disease with no other likely explanation. The more specific an association between a factor and an effect is, the bigger the probability of a causal relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temporality**: The effect has to occur after the cause (and if there is an expected delay between the cause and expected effect, then the effect must occur after that delay)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Biological gradient**: Greater exposure should generally lead to greater incidence of the effect. However, in some cases, the mere presence of the factor can trigger the effect. In other cases, an inverse proportion is observed: greater exposure leads to lower incidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plausibility**: A plausible mechanism between cause and effect is helpful (but Hill noted that knowledge of the mechanism is limited by current knowledge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coherence**: Coherence between epidemiological and laboratory findings increases the likelihood of an effect. However, Hill noted that \"... lack of such [laboratory] evidence cannot nullify the epidemiological effect on associations\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**: \"Occasionally it is possible to appeal to experimental evidence\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analogy**: The effect of similar factors may be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pearlean-causal-dag-model\"></a>\n",
    "## Pearlean Causal Directed Acyclic Graph (DAG) model\n",
    "\n",
    "---\n",
    "### Some quick background notes:\n",
    "- This is a visual tool to help us reason about causality and association\n",
    "- It was proposed by Judea Pearl, although there are many similar models\n",
    "- We will only scratch the surface, so look into other resources if you find this interesting\n",
    "    - We cover the basic idea and most notable cases\n",
    "    - We won't talk about the formal mathematics and probability underneath or how to use d-seperation to infer causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-a-dag\"></a>\n",
    "### What is a DAG?\n",
    "- DAG stands for directed acyclic graph, it's a collection of nodes connected by lines. \n",
    "- Each line has an arrow to point in a direction.\n",
    "- If you follow the arrows you reach a final node; there are no loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single circle or node in a Causal DAG represents an event, something that happens at one point in time.\n",
    "\n",
    "![](./assets/images/dag1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend the random variables X and Y, or two different types of events, are correlated with each other.\n",
    "\n",
    "**What are the possible causal structures that will give us this correlation?**\n",
    "- X causes Y\n",
    "- Y causes X\n",
    "- There is no actual causation\n",
    "- X or Y indirectly causes the other\n",
    "- There is a third factor that causes both\n",
    "- X and Y cause a third factor, but our data collects the third factor unevenly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"its-possible-that-x-causes-y\"></a>\n",
    "### It's possible that X causes Y.\n",
    "![](./assets/images/x-cause-y.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example where Y is a function of X:\n",
    "X = np.random.randn(100)\n",
    "Y = 5 + 2*X + np.random.randn(100)\n",
    "dag = pd.DataFrame({'X':X, 'Y':Y})\n",
    "\n",
    "# make a pairplot of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"y-causes-x\"></a>\n",
    "### Y causes X.\n",
    "![](./assets/images/y-cause-x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example where X is a function of Y:\n",
    "Y = np.random.randn(100)\n",
    "X = 5 + 2*Y + np.random.randn(100)\n",
    "dag = pd.DataFrame({'X':X, 'Y':Y})\n",
    "\n",
    "# make a pairplot of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"the-correlation-between-x-and-y-is-not-statistically-significant\"></a>\n",
    "### The correlation between X and Y is not statistically significant.\n",
    "![](./assets/images/xy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No correlation between X and Y:\n",
    "X = np.random.randn(100)\n",
    "Y = 5 + np.random.randn(100)\n",
    "dag = pd.DataFrame({'X':X, 'Y':Y})\n",
    "\n",
    "# make a pairplot of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"x-or-y-may-cause-one-or-the-other-indirectly-through-another-variable\"></a>\n",
    "### X or Y may cause one or the other indirectly through another variable.\n",
    "![](./assets/images/x-c-z-y.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y is a function of Z, and Z is a function of X:\n",
    "X = 5 + np.random.randn(100)\n",
    "Z = X + 0.1*np.random.randn(100)\n",
    "Y = 3 + Z + np.random.randn(100)\n",
    "\n",
    "dag = pd.DataFrame({'X':X, 'Y':Y, 'Z':Z})\n",
    "\n",
    "# make a pairplot of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"there-is-a-third-common-factor-that-causes-both-x-and-y\"></a>\n",
    "### There is a third common factor that causes both X and Y.\n",
    "![](./assets/images/z-cause-xy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Both X and Y are functions of Z:\n",
    "Z = np.random.randn(100)\n",
    "\n",
    "X = 5 + 2*Z + np.random.randn(100)\n",
    "Y = 3 + 3*Z + np.random.randn(100)\n",
    "common_cause = pd.DataFrame({'X':X, 'Y':Y, 'Z':Z})\n",
    "\n",
    "# make a pairplot of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"both-x-and-y-cause-a-third-variable-and-the-dataset-does-not-represent-that-third-variable-evenly\"></a>\n",
    "### Both X and Y cause a third variable and the dataset does not represent that third variable evenly.\n",
    "\n",
    "![](./assets/images/xy-causez.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Z is a function of X and Y:\n",
    "X = 5 + np.random.randn(100)\n",
    "Y = 3 + np.random.randn(100)\n",
    "Z = X + Y + 0.1*np.random.randn(100)\n",
    "common_effect = pd.DataFrame({'X':X, 'Y':Y, 'Z':Z})\n",
    "\n",
    "# make a pairplot of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, recovering the causality structure from a correlation matrix is difficult or impossible. However, thinking through causal effects can give you a much better intuition of your variables and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a \"confounder\"?\n",
    "\n",
    "Let’s say we did an analysis to understand what causes lung cancer. \n",
    "\n",
    "We find that people who carry cigarette lighters are 2.4 times more likely to contract lung cancer as people who don’t carry lighters.\n",
    "\n",
    "Does this mean that the lighters are causing cancer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted before, if lighters and cancer are both caused by smoking, there will be a correlation between lighters and cancer. This isn't the only possible diagram, but it makes the most sense.\n",
    "![](./assets/images/smoke-lighter-cancer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning on smoking by only looking at non-smokers, removes the correlation between lighters and cancer if we believe the above structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"controlled-experiments\"></a>\n",
    "### Controlled Experiments\n",
    "\n",
    "- The most foolproof way to measure an effect is to control all the confounders and to directly intervene and control our variable of interest. \n",
    "- This way we know that any correlation we find is not due to the confounders, but instead due to the variable we control. \n",
    "- This also means that all the effects we see are due to the variable we control.\n",
    "- However, experiments are not always possible, and take longer to create than using observational data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"when-is-it-ok-to-rely-on-association\"></a>\n",
    "### When is it OK to rely on association?\n",
    "\n",
    "- **When any intervention that arises from your model affects only the outcome variable.**\n",
    "    - In other words, you only need to predict y.\n",
    "    - This works because we only need to observe explanatory variables and implicitly know what the confounder is doing.\n",
    "    - Decision making and intervation due to your model are a hidden danger that can shift confounders\n",
    "    - You can always retrain your model to work with a new set of confounders if they shift.\n",
    "\n",
    "\n",
    "- **When correlation is causal**\n",
    "    - If you are sure there are no confounding factors or selection bias, then that association might be a causation (risky)\n",
    "    - It's OK to exclude confounders that have very unlikely or small effects\n",
    "    - This is a saving grace. To have a good model you only need variables that correlate with your outcome.\n",
    "        - Those variables merely need to meaningfully correlate with your outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-does-association-relate-to-causation\"></a>\n",
    "### How does association relate to causation?\n",
    "\n",
    "Most commonly, we find an association between two variables.\n",
    "- There is an observed correlation between the variables.\n",
    "- There is an observed correlation in a subset of data.\n",
    "- We find that the descriptive statistics significantly differ in two subsets of the data.\n",
    "\n",
    "We may still not fully understand the causal direction (e.g. does smoking cause cancer or does cancer cause smoking?).\n",
    "- A causes B, B causes A, or a third factor causes both.\n",
    "    - A and B never cause each other!\n",
    "\n",
    "We also might not understand other factors influencing the association."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confounding variables often hide the true association between causes and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Directed Acyclic Graph (DAG) can help determine which variables are most important for your model.  It helps visually demonstrate the logic of your models.\n",
    "\n",
    "A DAG always includes at least one exposure/predictor and one outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codealong: Explore the associations in the advertising data\n",
    "\n",
    "#### Visualize the relationship between the features and the response using scatterplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there a relationship between ads and sales? Which type of ads?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can we say this a causal relationship?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What other questions might we want to know about this data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Exercise: evaluate which type of ad is associated with higher sales.\n",
    "\n",
    "Let's say we want to evaluate which type of ad is associated with higher sales.\n",
    "\n",
    "1. Draw a basic DAG on your table or whiteboard.\n",
    "- Think about other variables that may predict sales.\n",
    "- Think about confounding causes.\n",
    "- Think about downstream effects changing investement in advertising.\n",
    "- Be ready to share an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section Summary\n",
    "\n",
    "1) **The importance of having deep subject area knowledge.** You'll develop this over time and it will help you move through your analysis in a logical manner. However, keep in mind that you can show a strong association and still be totally wrong.\n",
    "\n",
    "2) **A DAG (directed acyclic graph) can be a handy tool for thinking through the logic of your models.**\n",
    "\n",
    "3) **The distinction between causation and correlation.** In our smoking example, it's relatively obvious that there's a flaw in our logic; however, this won't always be so readily apparent... especially in cutting edge fields where there are many other unknown variables.\n",
    "\n",
    "4) **The importance of good data.** Throughout the class we will be working on helping you develop your data intuition, so that you can spot gaps and bias more readily. With this will come a bunch of tools to help you. However, your analysis is only as good as your understanding of the problem and the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sampling-bias\"></a>\n",
    "## Sampling bias\n",
    "---\n",
    "\n",
    "**Sampling bias** occurs when a sample is collected in such a way that some members of the intended population are more or less likely to be included than others.\n",
    "\n",
    "This can happen when a sample is taken non-randomly, either implicitly or explicitly.\n",
    "\n",
    "When we have non-random sampling that results in sampling bias this can affect the inferences or results of our analyses. We must be sure not to attribute our results to the process we observe when it could actually be due to non-random sampling.\n",
    "\n",
    "This is conceptually straightforward: when we have sampling bias we aren't measuring what we think we are measuring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"forms-of-sampling-bias\"></a>\n",
    "### Examples of sampling bias\n",
    "\n",
    "- **Pre-screening:** Purposely restricting the sample to a specific group or region.\n",
    "    - This typically happens when people try to study priority areas to save costs and assume priority areas are the same as random areas.\n",
    "- **Self-selection:** When someone has the ability to non-randomly decide what gets included in our sample.\n",
    "    - This typically happens in surveys and polls, but can also be an issue with other kinds of reporting.\n",
    "- **Survivorship bias:** When we select only surviving subjects in a sample over time.\n",
    "    - This might happen when we only look at existing customers and assume they have the same characteristics as new incoming customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"problems-from-sampling-bias\"></a>\n",
    "### Problems that arise from sampling bias\n",
    "- We will overestimate or underestimate means and sample statistics for simple characteristics.\n",
    "- It's possible to have artificial correlation where there should be none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"recovering-from-sampling-bias\"></a>\n",
    "### Recovering from sampling bias\n",
    "- Working out causal DAGs can help you identify when you need to watch out for sample bias\n",
    "- Generally, it's best to prevent sample bias whenever possible\n",
    "- We can't really do anything if we ENTIRELY exclude an important group of data\n",
    "- However, if portions of our data are overrepresented or underrepresented, there are ways to correct the effect.\n",
    "    - Typically, we explicitly model the selection process, which means we need data on factors that determine whether someone participates or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stratified-random-sampling\"></a>\n",
    "### Stratified random sampling\n",
    "\n",
    "We discussed above that it is important to obtain a random sample of our population. However, sometimes it is more effective to apply some reasoning to our sampling process. By optimizing how we choose samples, we can possibly make a more accurate model using fewer samples.\n",
    "\n",
    "- **Stratified random sampling** ensures we capture important population characteristics in the random sample. If we know that the population is half males and half females, for example, we can make sure that our sample is half male and half female. We effectively break the population into two \"strata\" (groups), then randomly sample from each group to obtain our overall sample. This method is similar to taking a weighted average and depends on knowing key population statistics.\n",
    "\n",
    "    - For example, if we are collecting survey data, we might ensure our participants are evenly split between men and women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-data\"></a>\n",
    "## Missing data\n",
    "---\n",
    "\n",
    "Sometimes we are unable to collect every attribute for a particular observation. \n",
    "\n",
    "Unfortunately, this makes the observation unusable until we decide how to deal with it.\n",
    "\n",
    "**We have to decide whether to:**\n",
    "- Drop the observation\n",
    "- Drop the attribute\n",
    "- Impute a value for that specific attribute and observation\n",
    "\n",
    "**How do we decide?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"types-of-missing-data\"></a>\n",
    "### Types of missing data\n",
    "- **Missing completely at random (MCAR)**\n",
    "    - The reason that the data is missing is completely random and introduces no sampling bias\n",
    "    - In this case it's very safe to drop or impute\n",
    "    - We can test for this by looking at other attribute for missing and non-missing groups to see if they match\n",
    "\n",
    "\n",
    "- **Missing at random (MAR)**\n",
    "    - The data is missing in a way that is related to another factor\n",
    "    - This is a form of sampling bias\n",
    "    - Like other sampling bias, we can fix this by modeling the selection process\n",
    "        - This is done by building a model to impute the missing value based on other variables\n",
    "\n",
    "\n",
    "- **Missing not at random (MNAR)**\n",
    "    - The response is missing in a way that relates to its own value\n",
    "    - We can't test for this\n",
    "    - We also can't fix this in a reasonable way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"de-minimis\"></a>\n",
    "### De minimis\n",
    "- If few enough observations are missing, it's not likely to change our results to a meaningful degree.\n",
    "- In these case, we don't have to bother with trivialities and just pick a method that works well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"class-imbalance\"></a>\n",
    "### Class imbalance\n",
    "\n",
    "Sometimes, a sample may include an overrepresented sample of one type of class. For example, airport security may have 990 xray scans showing the absence of a weapon. Due to natural scarcity, they may provide only 10 scans showing a weapon.\n",
    "\n",
    "- If our goal is to create a model that indicates whether a weapon is present, then we are at a disadvantage. **Ignoring the class imbalance** would lead to a model that simply always guesses that a weapon is not present!\n",
    "    - Note that most optimization procedures optimize for training data accuracy. Always guessing that a weapon is absent leads to 990/1000 correct, an accuracy of 99%.\n",
    "\n",
    "\n",
    "- A simple way to get around this is to **undersample** the majority class, deliberately leaving us with a balanced dataset of 10 each. However, this is less than ideal since it effectively ignores much of the available data.\n",
    "\n",
    "- We could alternatively **oversample** the minority class by duplicating examples. Again, this is not ideal. Because we have very little data, this will magnify small differences that may just be error, leading to a model that overfits.\n",
    "\n",
    "Later in the course, we will look at additional methods for training models to get around class imbalance. For example, we may use an optimization algorithm that cares less about accuracy and more about minimizing particular types of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relation-to-machine-learning\"></a>\n",
    "### Relation to machine learning\n",
    "\n",
    "Many of the topics discussed in this lesson are used both in statistics and machine learning. However, some of the terminology differs. \n",
    "\n",
    "Throughout this lesson, we have discussed **variables** (typically **independent variables** and **dependent variables**). For example, we might be given the **linear estimator** $Y = mX + b$. We could say this contains two variables ($X$ - independent, and $Y$ - dependent (i.e. the prediction) since it depends on $X$), a coefficient $m$, and the constant $b$.\n",
    "\n",
    "In machine learning, we typically rewrite this as a function, $\\hat{y}(x) = mx + b$, and call it a **linear model**. The predicted value is $\\hat{y}(x)$ (\"prediction\" is denoted by the carat) which is dependent on $x$. We might call $x$ a **feature** rather than a variable.\n",
    "\n",
    "> **Example:** Suppose the house price $P$ is linearly dependent on the square footage $S$. So, we might predict $P = cS + b$, where $c$ and $b$ are constants. Alternatively, we could write $\\hat{p}(s) = cs + b$. Here, we took a complicated house and modeled it using a single feature, its square footage. Of course, we are likely missing many confounding variables/features that also affect the price! So, our model likely has a lot of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction-to-hypothesis-testing\"></a>\n",
    "## Introduction to Hypothesis Testing\n",
    "---\n",
    "\n",
    "#### Objective: Test a hypothesis within a sample case study\n",
    "\n",
    "You'll remember from last time that we worked on descriptive statistics such as mean and variance. How would we tell if there is a difference between our groups? How would we know if this difference was real or if our finding is simply due to chance?\n",
    "\n",
    "For example, if we are working on sales data, how would we know if there was a difference between the buying patterns of men and women at Acme Inc? Hypothesis testing!\n",
    "\n",
    "> **Note:** In this class, hypothesis testing is primarily used to assess foundational models such as linear and logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing steps\n",
    "\n",
    "Generally speaking, we start with a **null hypothesis** and an **alternative hypothesis**, which is opposite the null. Then, you check whether the data supports rejecting your null hypothesis or fails to reject the null hypothesis.\n",
    "\n",
    "For example:\n",
    "\n",
    "    Null hypothesis: There is no relationship between Gender and Sales.\n",
    "    Alternative hypothesis: There is a relationship between Gender and Sales\n",
    "\n",
    "Note that \"failing to reject\" the null is not the same as \"accepting\" the null hypothesis. Your alternative hypothesis may indeed be true, but you don't necessarily have enough data to show that yet.\n",
    "\n",
    "This distinction is important to help you avoid overstating your findings. You should only state what your data and analysis can truly represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validate-your-findings\"></a>\n",
    "### Validate your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How do we tell if the association we observed is statistically significant?\n",
    "\n",
    "Statistical Significance is the likelihood that a result or relationship is caused by something other than mere random chance. Statistical hypothesis testing is traditionally employed to determine if a result is statistically significant or not.\n",
    "\n",
    "We ask: **how likely is the effect observed to be true, assuming the null hypothesis is true?**. If there is less than a 5% chance of observing what we observed by chance (supposing the null hypothesis), then we reject the null hypothesis. Note that the 5% value is in many ways arbitrary -- many statisticians require even higher confidence levels.\n",
    "\n",
    "The probability of our observations occuring by chance, given the null hypothesis, is the **p-value** $p$.\n",
    "\n",
    "---\n",
    "\n",
    "**Example:** Suppose you flip a coin three times and get three heads in a row. These three flips are our observations.\n",
    "\n",
    "+ We want to know whether the coin is fair or not. So, we select the **null hypothesis: The coin is fair.**\n",
    "+ Now, let's suppose the null hypothesis is true. Three heads in a row occurs with chance $1/2^3 \\approx 12.5\\%$.\n",
    "+ Because there is a reasonable ($> 5\\%$) chance of three heads occuring naturally, we do not reject the null hypothesis.\n",
    "+ So, **we conclude:** we do not have enough data to tell whether the coin is fair or not, $p = 0.125$.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In other words, we say that something is NOT statistically significant if there is a less than 5% chance that our finding was due to chance alone (assuming the null hypothesis is true)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"confidence-intervals\"></a>\n",
    "### Confidence intervals\n",
    "\n",
    "A closely related concept is **confidence intervals**. A 95% confidence interval can be interpreted as follows: If the population from which this sample was drawn was **sampled 100 times**, approximately **95 of those samples** would contain an effect at least as large as the one we measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Keep in mind that we only have a **single sample of data**, and not the **entire population of data**. The \"true\" effect/difference is either within this interval or it isn't, but there's no way to actually know. We estimate the difference with the data we do have, and we show uncertainty about that estimate by giving a range that the difference is **probably** within.\n",
    "\n",
    "Note that using 95% confidence intervals is just a convention. You can create 90% confidence intervals (which will be more liberal), 99% confidence intervals (which will be more conservative), or whatever intervals you like.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"error-types\"></a>\n",
    "### Error types\n",
    "\n",
    "Statisticians often classify errors not just as errors, but as two specific types of errors -- Type I and Type II.\n",
    "\n",
    "+ **Type I Errors** are false positives.\n",
    "    - Machine learning: Our model falsely predicts \"positive\". (The prediction is incorrect.)\n",
    "    - Statistics: Incorrect rejection of a true null hypothesis.\n",
    "\n",
    "\n",
    "+ **Type II Errors** are false negatives.\n",
    "    - Machine learning: Our model falsely predicts \"negative\". (The prediction is incorrect.)\n",
    "    - Statistics: Incorrectly retaining a false null hypothesis.\n",
    "\n",
    "\n",
    "Understanding these errors can be very beneficial when designing models. For example, we might decide that Type I errors are okay but Type II errors are not okay. We can then optimize our model appropriately.\n",
    "\n",
    "> **Example:** Suppose we make a model for airline security where we predict whether a weapon is present (\"positive\"). In this case, we would much rather have Type I errors (falsely predict a weapon) than Type II errors (falsely predict no weapon).\n",
    "\n",
    "> **Example:** Suppose we make a model for the criminal justice system, predicting whether a defendant is guilty (\"positive\"). In this case, we would much rather have Type II errors (falsely predict innocent) than Type I errors (falsely predict guilty).\n",
    "\n",
    "Can you phrase these examples in terms of null hypotheses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Challenge: A/B Testing Hypothesis tests\n",
    "\n",
    "<a id=\"scenario\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You are a data science team working for a web-based company and you are planning to roll out a new site design soon. For random samples of users one of two competing designs were presented and the ultimate purchase total was recorded (if any).\n",
    "\n",
    "Your task is to determine which of the two designs yields higher total purchases, and if the result is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.685473</td>\n",
       "      <td>25.666710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.152146</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.274252</td>\n",
       "      <td>18.370134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.122102</td>\n",
       "      <td>26.632519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.228489</td>\n",
       "      <td>25.862179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A          B\n",
       "0  14.685473  25.666710\n",
       "1  20.152146   0.000000\n",
       "2  14.274252  18.370134\n",
       "3  12.122102  26.632519\n",
       "4  18.228489  25.862179"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some data and randomize\n",
    "\n",
    "# Some people bought nothing, the others bought \n",
    "# with some distribution\n",
    "data1 = [0] * 50\n",
    "data1.extend(np.random.normal(14, 4, 150))\n",
    "np.random.shuffle(data1)\n",
    "\n",
    "# The second design hooked less people, \n",
    "# but those that were hooked bought more stuff\n",
    "data2 = [0] * 100\n",
    "data2.extend(np.random.normal(20, 5, 100))\n",
    "np.random.shuffle(data2)\n",
    "\n",
    "# Make a data frame\n",
    "df = pd.DataFrame()\n",
    "df[\"A\"] = data1\n",
    "df[\"B\"] = data2\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot out the distributions of group A and group B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a boxplot and a violin plot of the two groups using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the violin plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the boxplot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are our datasets (approximately) normal? Use what we learned in the previous lesson to decide.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the distributions for group A and B. Are they approximately normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"statistical-tests\"></a>\n",
    "### Statistical Tests\n",
    "\n",
    "There are a few good statistical tests for A/B testing:\n",
    "* [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance)\n",
    "* [Welch's t-test](https://en.wikipedia.org/wiki/Welch's_t-test)\n",
    "* [Mann-Whitney test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)\n",
    "\n",
    "**Each test makes various assumptions:**\n",
    "* ANOVA assumes the residuals are normally distributed and data has equal variances\n",
    "* The Welch t-test assumes normal distributions but not necessarily equal variances, and accounts for small sample sizes better\n",
    "* The Mann-Whitney test assumes nothing about the distributions but requires at least 20 data points in each set, and produces a weaker p-value\n",
    "\n",
    "Typically you need to choose the most appropriate test. Tests that make more assumptions are more discriminating (stronger p-values) but can be misleading on data sets that don't satisfy the assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which test is most appropriate for our data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, **one-way analysis of variance** (abbreviated one-way **ANOVA**) is a technique used to compare means of three or more samples (using the **F distribution**). The **ANOVA** tests the **null hypothesis** (default position that there is no relationship) that samples in two or more groups are drawn from populations with the same mean values. Typically, however, the **one-way ANOVA** is used to test for differences among at least three groups, since the two-group case can be covered by a **t-test**. When there are only two means to compare, the **t-test** and the **F-test** are equivalent.\n",
    "\n",
    "> **Note:**  One-Way ANOVA: An ANOVA hypothesis tests the difference in population means based on one characteristic or factor.\n",
    "\n",
    "> Two-Way ANOVA: An ANOVA hypothesis tests comparisons between populations based on multiple characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the Mann-Whitney test on our data**\n",
    "\n",
    "- look up the function in scipy from the link below\n",
    "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html\n",
    "- statistic : float The Mann-Whitney U statistic, equal to min(U for x, U for y) if alternative is equal to None (deprecated; exists for backward compatibility), and U for y otherwise.\n",
    "- pvalue : float p-value assuming an asymptotic normal distribution. One-sided or two-sided, depending on the choice of alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mann–Whitney U test (also called the Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, or Wilcoxon–Mann–Whitney test) is a nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample.\n",
    "\n",
    "Unlike the t-test it does not require the assumption of normal distributions. It is nearly as efficient as the t-test on normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"interpret-your-results\"></a>\n",
    "### Interpret your results\n",
    "* Is there a significant difference in the mean total purchases in the two designs?\n",
    "* Which design do you recommend and why? \n",
    "* Write two sentences explaining your results and your recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
